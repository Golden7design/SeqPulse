# SeqPulse - Priorit√©s d'Architecture

**Date de cr√©ation:** 2026-02-06
**Auteur:** Satoru (IA Senior Architect)
**Projet:** SeqPulse - Monitoring intelligent de d√©ploiement

---

## üö® CRITICAL (Bloqueurs) - √Ä corriger IMM√âDIATEMENT

### 1. Scheduler: Zero Persistence
**Probl√®me:** Le scheduler actuel utilise `threading.Thread` et `threading.Timer` ‚Äî si le backend crash (OOM, restart, deploy), TOUS les scheduled jobs sont perdus.

**Impact:**
- D√©ploiements sans analyse si le backend red√©marre
- Pas de m√©canisme de recovery automatique
- Impossible de monitorer l'√©tat des t√¢ches

**Solution Recommand√©e:** Custom Job Table + Poller (MVP)
- Cr√©er table `scheduled_jobs` avec colonnes: id, deployment_id, job_type, phase, scheduled_at, status (pending/running/completed/failed), retry_count, last_error
- Background poller (cron every 10s) qui:
  1. S√©lectionne les jobs `pending` avec `scheduled_at <= now()`
  2. Marque comme `running`
  3. Ex√©cute la t√¢che
  4. Met √† jour le statut (completed/failed) avec retry logic
- Avantages: Persistant, inspectable en DB, simple √† impl√©menter, pas de Redis/Celere

**Alternative Future:** Celere + Redis (production-grade) si tu scales

---

### 2. Race Condition dans `analyze_deployment`
**Probl√®me:** Pas de lock row-level sur le deployment avant analyse. Deux appels concurrents peuvent cr√©er deux verdicts, dupliquer les SDH hints.

**Impact:**
- Donn√©es dupliqu√©es en DB
- Incoh√©rence dans les r√©sultats UI
- Probl√®mes de confiance dans les verdicts

**Solution:** Deux approches possibles:

**Option 1: Idempotent INSERT (recommand√©)**
```sql
INSERT INTO deployment_verdicts (deployment_id, verdict, ...)
VALUES (...)
ON CONFLICT (deployment_id) DO NOTHING;
```

**Option 2: Row-level Lock**
```python
deployment = db.query(Deployment).filter_by(id=deployment_id).with_for_update().one()
# ... analyse
```

---

### 3. Error Handling & Retries Absolants
**Probl√®me:** Si `/ds-metrics` renvoie 503/timeout, la collecte √©choue sans retry. Les partial failures ne sont pas g√©r√©es.

**Impact:**
- Analyses incompl√®tes (samples manquants)
- Verdicts peu fiables
- Pas de recovery automatique

**Solution:** Retry logic avec exponential backoff
```python
MAX_RETRIES = 3
RETRY_DELAYS = [5, 15, 30]  # seconds

for attempt, delay in enumerate(RETRY_DELAYS + [None]):
    try:
        collect_metrics(...)
        return
    except (httpx.RequestError, ValueError) as e:
        if delay is None:
            raise
        time.sleep(delay)
```

---

### 4. Blocking Threads dans `schedule_post_collection`
**Probl√®me:** Chaque d√©ploiement bloque un thread pendant `observation_window √ó 60s`. 20 d√©ploiements concurrents = 20 threads bloqu√©s.

**Impact:**
- Scalabilit√© limit√©e
- Performance d√©grad√©e sous load
- Possibilit√© de deadlock si trop de threads en attente

**Solution:** Split en tasks individualuelles
```python
# Au lieu d'une boucle bloquante, lance N tasks individuelles
for i in range(observation_window):
    schedule_post_collect_single(
        deployment_id=deployment_id,
        sequence_index=i,
        delay_seconds=i * 60,  # 0s, 60s, 120s...
        metrics_endpoint=...
    )
```

---

## ‚ö†Ô∏è HIGH (Importants) - √Ä corriger sous 2-4 semaines

### 5. Missing Idempotency dans plusieurs endpoints
**Probl√®me:** Plusieurs API endpoints ne sont pas idempotents. Un double appel cr√©erait des duplicates.

**Impact:** Donn√©es corrompues par des retries accidentels

**Solution:** Utiliser `ON CONFLICT DO NOTHING` ou locks row-level pour toutes les op√©rations de cr√©ation.

---

### 6. No Structured Logging
**Probl√®me:** Les logs utilisent `print()` et `logger.warning()` sans structure coh√©rente.

**Impact:**
- Impossible de tracer un deployment end-to-end
- Difficile de debuguer en production
- Pas de logs JSON pour ingestion dans ELK/Graylog

**Solution:** Int√©grer `structlog` ou `python-json-logger`
```python
logger.info(
    "metrics_collected",
    deployment_id=str(deployment_id),
    phase=phase,
    latency_avg=post_agg["latency_p95"],
    duration_ms=duration
)
```

---

### 7. No Healthcheck Monitoring
**Probl√®me:** Le `/health` endpoint existe mais ne v√©rifie pas:
- Que le scheduler poller est actif
- Que la DB connecte correctement
- Que les tasks ne sont pas stuck en state `pending`

**Impact:** Impossible de savoir si le syst√®me est healthy en production

**Solution:** Healthcheck enrichi
```python
@app.get("/health")
def health(db: Session = Depends(get_db)):
    checks = {
        "db": db_check(db),
        "scheduler_last_heartbeat": get_scheduler_last_heartbeat(),
        "pending_jobs_count": get_pending_jobs_count(),
    }
    all_healthy = all(checks.values())
    return {"status": "ok" if all_healthy else "degraded", "checks": checks}
```

---

### 8. Missing Metrics (Prometheus/StatsD)
**Probl√®me:** Aucune m√©trique expos√©e pour monitorer SeqPulse lui-m√™me.

**Impact:** Impossible de cr√©er des dashboards Grafana, d'alerter sur anomalies

**Solution:** Int√©grer `prometheus_client`
```python
from prometheus_client import Counter, Histogram

metrics_collected_total = Counter('seqpulse_metrics_collected_total', 'Total metrics collected')
analysis_duration = Histogram('seqpulse_analysis_duration_seconds', 'Analysis duration')
```

---

## üîç MEDIUM (Am√©liorations) - √Ä corriger sur la roadmap

### 9. Coverage de Tests Incompl√®te
**Probl√®me:** Tests existent mais couverture insuffisante, sp√©cialement pour:
- SDH logic (r√®gles de diagnostics complexes)
- Scheduler edge cases (concurrent analyses)
- HMAC security (replay attacks, TTL skew)

**Impact:** Refactors risqu√©s, bugs possibles

**Solution:** Prioriser SDH tests en premier (core de la valeur ajout√©e)

---

### 10. No Metrics Archiving Strategy
**Probl√®me:** `metric_samples` va grossir ind√©finiment. Pas de strat√©gie de purging/archivage.

**Impact:** DB performance d√©grade avec le temps, storage cost explose

**Solution:**
- Court terme: Cron job qui supprime les samples > 30 jours
- Long terme: Migrate vers TimescaleDB/ClickHouse pour time-series optimization

---

### 11. Frontend Dashboard Incomplet
**Probl√®me:** Frontend a structure mais pas toutes les pages impl√©ment√©es.

**Impact:** Exp√©rience utilisateur incompl√®te

**Solution:** Priorit√©:
1. Dashboard principal (overview)
2. Deployment detail (timeline, charts, SDH)
3. SDH page (filter by severity)
4. Projects management

---

### 12. No Rate Limiting sur `/ds-metrics`
**Probl√®me:** Si un projet abuse de l'endpoint de metrics, il peut DDoS le backend.

**Impact:** Instabilit√© potentielle sous abuse

**Solution:** Int√©grer `slowapi` ou `fastapi-limiter`
```python
@app.get("/ds-metrics")
@limiter.limit("10/minute")
def get_metrics(...):
```

---

## ‚úÖ POINTS FORTS √Ä CONSERVER

### Excellences Architecturelles
1. **SDH Intelligent:** Diagnostics multi-metrics composites ‚Äî c'est ta valeur ajout√©e unique
2. **HMAC Security:** Implementation robuste avec canonicalization, nonce, TTL
3. **Database Models:** Relations SQLAlchemy propres, CASCADE delete correct, index bien plac√©s
4. **Separation of Concerns:** Modules bien isol√©s (scheduler, collector, analysis, SDH)
5. **Configuration Dynamique:** Plans Free/Pro avec observation_windows variables

---

## üìã PLAN D'ACTION RECOMMAND√â

### Week 1-2: Critical Fixes
- [ ] Refactor scheduler ‚Üí Custom Job Table + Poller
- [ ] Fix race conditions dans `analyze_deployment`
- [ ] Add retry logic pour metric collections
- [ ] Unbloquer threads dans post collection (split tasks)

### Week 3-4: High Priority
- [ ] Structured logging (structlog)
- [ ] Healthcheck enrichi (scheduler monitoring)
- [ ] Basic metrics exposure (prometheus_client)
- [ ] Idempotency sur tous les endpoints

### Week 5-8: Medium Priority
- [ ] Compl√©ter frontend dashboard
- [ ] SDH tests (priorit√© absolue)
- [ ] Metrics archiving strategy
- [ ] Rate limiting sur `/ds-metrics`

---

## üéØ MESURES DE SUCC√àS

### Avant Fix Critiques
- Scheduler: **0% persistence** (jobs perdus si crash)
- Race conditions: **non prot√©g√©**
- Retries: **absent**
- Thread blocking: **scalabilit√© limit√©e**

### Apr√®s Fixes Critiques
- Scheduler: **100% persistence** (jobs en DB, recovery auto)
- Race conditions: **0 chance** (ON CONFLICT locks)
- Retries: **3 attempts** avec exponential backoff
- Thread blocking: **0 blocking** (tasks async)

---

## üìä METRICS TARGETS

- **Scheduler Uptime:** > 99.9%
- **Metric Collection Success Rate:** > 95% (avec retries)
- **Analysis Latency:** < 2s apr√®s collection POST
- **DB Connection Pool:** < 50% usage normal
- **Queue Depth:** < 10 pending jobs normal

---

## üöÄ PROCHAINES √âTAPES

1. **Commen√ßons par le scheduler refactor** ‚Äî c'est le fondement d'un syst√®me production-ready
2. **Tester √† fond** chaque fix avec load tests
3. **Mettre en prod** les fixes critiques avant d'ajouter des features
4. **Monitorer** avec les nouvelles metrics expos√©es

Tu veux que je te guide sur l'une de ces priorit√©s en particulier ? Le scheduler refactor est le meilleur point de d√©part pour stabiliser le syst√®me. üéØ